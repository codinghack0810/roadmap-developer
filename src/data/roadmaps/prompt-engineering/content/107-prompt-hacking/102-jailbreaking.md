# Jailbreaking

Jailbreaking, in the context of prompt engineering, is a technique used to enable the assistant to provide outputs that may be considered beyond its normal limitations. This is often compared to the process of jailbreaking a smartphone, which allows users to unlock certain restrictions and access additional features that would not be otherwise available.

Jailbreaking the assistant involves carefully designing the prompt to encourage the AI to act resourcefully and generate information which can be both creative and useful. Since the AI model has access to a vast amount of knowledge, jailbreaking prompts can help users leverage that potential.

Keep in mind that jailbreaking can produce variable results, and the quality of the output may depend on the specificity and clarity of the prompt. Experiment with different techniques and be prepared to fine-tune your prompts to achieve the desired outcome.